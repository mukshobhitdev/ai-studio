{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9eea096",
   "metadata": {},
   "source": [
    "\n",
    "# Classify Reviews\n",
    "\n",
    "To install packages that are not installed by default,\n",
    "uncomment the last line of this cell and replace with a list of needed packages.\n",
    "\n",
    "This will ensure the notebook has all the dependencies and works everywhere.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818bfaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "# Uncomment and run if you need to install packages in this environment\n",
    "!{sys.executable} -m pip install pandas numpy torch scikit-learn matplotlib seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb7cfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, random, time, os\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 101)\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device:', device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a409f961",
   "metadata": {},
   "source": [
    "\n",
    "## Data Description\n",
    "\n",
    "Column | Description\n",
    "---|---\n",
    "`title` | Title of the review\n",
    "`review` | Review text\n",
    "`recommendation` | Will the user recommend the product or not (0=No, 1=Yes)\n",
    "\n",
    "Load the training and test datasets (place `train.csv` and `test.csv` in the same folder as this notebook).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8e6160",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_path = \"train.csv\"\n",
    "test_path  = \"test.csv\"\n",
    "\n",
    "if not os.path.exists(train_path):\n",
    "    raise FileNotFoundError(f\"{train_path} not found. Please upload it to the current directory.\")\n",
    "if not os.path.exists(test_path):\n",
    "    raise FileNotFoundError(f\"{test_path} not found. Please upload it to the current directory.\")\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df  = pd.read_csv(test_path)\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Test  shape:\", test_df.shape)\n",
    "display(train_df.head(3))\n",
    "display(test_df.head(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c820e575",
   "metadata": {},
   "source": [
    "\n",
    "## Preprocessing & Vocabulary\n",
    "\n",
    "- Combine `title` and `review` into one text field.\n",
    "- Clean (lowercase, remove non-alphanumerics) and tokenize using whitespace.\n",
    "- Build a vocabulary with minimum frequency filtering.\n",
    "- Encode sequences and pad to fixed length.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e946d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_text(df: pd.DataFrame) -> pd.Series:\n",
    "    title = df.get(\"title\", pd.Series([\"\"]*len(df))).fillna(\"\")\n",
    "    review = df.get(\"review\", pd.Series([\"\"]*len(df))).fillna(\"\")\n",
    "    text = (title + \" \" + review).str.strip()\n",
    "    return text\n",
    "\n",
    "_non_alnum_re = re.compile(r\"[^a-z0-9\\s]+\")\n",
    "_multi_space_re = re.compile(r\"\\s+\")\n",
    "\n",
    "def clean(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = _non_alnum_re.sub(\" \", text)\n",
    "    text = _multi_space_re.sub(\" \", text).strip()\n",
    "    return text\n",
    "\n",
    "def tokenize(text: str):\n",
    "    return clean(text).split()\n",
    "\n",
    "train_texts = build_text(train_df)\n",
    "test_texts  = build_text(test_df)\n",
    "\n",
    "min_freq = 2\n",
    "counter = Counter()\n",
    "for t in train_texts:\n",
    "    counter.update(tokenize(t))\n",
    "for t in test_texts:\n",
    "    counter.update(tokenize(t))\n",
    "\n",
    "PAD, UNK = \"<pad>\", \"<unk>\"\n",
    "vocab = {PAD: 0, UNK: 1}\n",
    "for tok, freq in counter.items():\n",
    "    if freq >= min_freq and tok not in vocab:\n",
    "        vocab[tok] = len(vocab)\n",
    "id2tok = {i: t for t, i in vocab.items()}\n",
    "vocab_size = len(vocab)\n",
    "print(\"Vocab size:\", vocab_size)\n",
    "\n",
    "train_lengths = np.array([len(tokenize(t)) for t in train_texts])\n",
    "p95 = int(np.percentile(train_lengths, 95)) if len(train_lengths) else 50\n",
    "max_len = int(max(8, min(300, p95)))\n",
    "print(\"Max sequence length:\", max_len)\n",
    "\n",
    "def encode(text: str, max_len: int = max_len):\n",
    "    toks = tokenize(text)\n",
    "    ids = [vocab.get(tok, vocab[UNK]) for tok in toks][:max_len]\n",
    "    if len(ids) < max_len:\n",
    "        ids = ids + [vocab[PAD]] * (max_len - len(ids))\n",
    "    return ids, min(len(toks), max_len)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af2f574",
   "metadata": {},
   "source": [
    "## Dataset class and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1241bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, max_len: int, has_labels: bool = True):\n",
    "        self.texts = build_text(df).tolist()\n",
    "        self.max_len = max_len\n",
    "        self.has_labels = has_labels\n",
    "        if self.has_labels:\n",
    "            self.labels = df['recommendation'].astype(int).tolist()\n",
    "        else:\n",
    "            self.labels = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ids, eff_len = encode(self.texts[idx], self.max_len)\n",
    "        item = {\n",
    "            'input_ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'lengths': torch.tensor(eff_len, dtype=torch.long)\n",
    "        }\n",
    "        if self.has_labels:\n",
    "            item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        return item\n",
    "\n",
    "train_df_, val_df_ = train_test_split(train_df, test_size=0.2, stratify=train_df['recommendation'], random_state=42)\n",
    "train_ds = ReviewDataset(train_df_, max_len=max_len, has_labels=True)\n",
    "val_ds   = ReviewDataset(val_df_,   max_len=max_len, has_labels=True)\n",
    "test_ds  = ReviewDataset(test_df,   max_len=max_len, has_labels=False)\n",
    "\n",
    "batch_size = 12\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, sampler=RandomSampler(train_ds))\n",
    "val_loader   = DataLoader(val_ds,   batch_size=batch_size, sampler=SequentialSampler(val_ds))\n",
    "test_loader  = DataLoader(test_ds,  batch_size=batch_size, sampler=SequentialSampler(test_ds))\n",
    "\n",
    "print('Dataset sizes -> train:', len(train_ds), 'val:', len(val_ds), 'test:', len(test_ds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6064f164",
   "metadata": {},
   "source": [
    "## BiLSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab647c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BiLSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size: int, embed_dim: int = 128, hidden_dim: int = 128, dropout: float = 0.3):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embed_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, 1)\n",
    "\n",
    "    def forward(self, input_ids, lengths):\n",
    "        x = self.embedding(input_ids)\n",
    "        output, (h_n, c_n) = self.lstm(x)\n",
    "        h_forward = h_n[-2, :, :]\n",
    "        h_backward = h_n[-1, :, :]\n",
    "        h = torch.cat([h_forward, h_backward], dim=1)\n",
    "        h = self.dropout(h)\n",
    "        logits = self.fc(h).squeeze(1)\n",
    "        return logits\n",
    "\n",
    "model = BiLSTMClassifier(vocab_size=vocab_size, embed_dim=128, hidden_dim=128, dropout=0.3).to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b5fcc2",
   "metadata": {},
   "source": [
    "## Training loop and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3275301",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(model, data_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_preds, all_targets = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            lengths   = batch['lengths'].to(device)\n",
    "            labels    = batch['labels'].to(device)\n",
    "\n",
    "            logits = model(input_ids, lengths)\n",
    "            loss = criterion(logits, labels)\n",
    "            total_loss += loss.item() * input_ids.size(0)\n",
    "\n",
    "            probs = torch.sigmoid(logits)\n",
    "            preds = (probs >= 0.5).long().cpu().numpy()\n",
    "            all_preds.extend(preds.tolist())\n",
    "            all_targets.extend(labels.long().cpu().numpy().tolist())\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader.dataset)\n",
    "    f1 = f1_score(all_targets, all_preds)\n",
    "    return avg_loss, f1, np.array(all_targets), np.array(all_preds)\n",
    "\n",
    "def train_model(model, train_loader, val_loader, epochs=8, lr=1e-3, weight_decay=0.0, patience=2):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    best_val_f1 = -1.0\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        t0 = time.time()\n",
    "\n",
    "        for batch in train_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            lengths   = batch['lengths'].to(device)\n",
    "            labels    = batch['labels'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(input_ids, lengths)\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * input_ids.size(0)\n",
    "\n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "        val_loss, val_f1, y_true, y_pred = evaluate(model, val_loader, criterion)\n",
    "        elapsed = time.time() - t0\n",
    "        print(f\"Epoch {epoch}/{epochs} | {elapsed:.1f}s  train_loss={train_loss:.4f}  val_loss={val_loss:.4f}  val_f1={val_f1:.4f}\")\n",
    "\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            epochs_no_improve = 0\n",
    "            best_state_dict = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve > patience:\n",
    "                print('Early stopping.')\n",
    "                break\n",
    "\n",
    "    if 'best_state_dict' in locals():\n",
    "        model.load_state_dict(best_state_dict)\n",
    "    print('Best val F1:', best_val_f1)\n",
    "    return model\n",
    "\n",
    "model = train_model(model, train_loader, val_loader, epochs=10, lr=1e-3, patience=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f29f67c",
   "metadata": {},
   "source": [
    "## Validation report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddca146",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "val_loss, val_f1, y_true, y_pred = evaluate(model, val_loader, criterion)\n",
    "print('Validation F1:', round(val_f1,4))\n",
    "print('\\nClassification report:\\n', classification_report(y_true, y_pred, digits=4))\n",
    "print('\\nConfusion matrix:\\n', confusion_matrix(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8774c37c",
   "metadata": {},
   "source": [
    "## Inference on test set & create submissions.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae40a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference and submission (minimal)\n",
    "model.eval()\n",
    "all_test_preds = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        lengths   = batch['lengths'].to(device)\n",
    "        logits = model(input_ids, lengths)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        preds = (probs >= 0.5).long().cpu().numpy()\n",
    "        all_test_preds.extend(preds.tolist())\n",
    "\n",
    "submission_df = test_df.copy()[['title','review']]\n",
    "submission_df['recommendation'] = np.array(all_test_preds, dtype=int).clip(0,1)\n",
    "submission_df.to_csv('submissions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
